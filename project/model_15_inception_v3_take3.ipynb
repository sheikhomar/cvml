{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-15-inception-v3-take3.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8YwySwir3hP_",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e6d6982-e71c-455b-836e-5be9f78049ce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525663207801,
          "user_tz": -120,
          "elapsed": 8378,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import urllib.request\n",
        "import h5py\n",
        "\n",
        "from keras import applications\n",
        "from keras.models import Model\n",
        "from keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x /= 255.\n",
        "    x -= 0.5\n",
        "    x *= 2.\n",
        "    return x\n",
        "\n",
        "\n",
        "class ModelBase:\n",
        "    def __init__(self,\n",
        "                 model_name=None,\n",
        "                 batch_size=16,\n",
        "                 verbose=0,\n",
        "                 n_freeze_layers=0,\n",
        "                 learning_rate=0.00001,\n",
        "                 epochs=400,\n",
        "                 optimizer='adam'\n",
        "                 ):\n",
        "        if model_name is None:\n",
        "            script_name, script_ext = os.path.splitext(sys.argv[0])\n",
        "            self.model_name = os.path.basename(script_name)\n",
        "        else:\n",
        "            self.model_name = model_name\n",
        "        self.batch_size = batch_size\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.train_data_dir = \"Train/TrainImages\"\n",
        "        self.validation_data_dir = \"Validation/ValidationImages\"\n",
        "        self.test_data_dir = \"Test/TestImages\"\n",
        "        self.img_width = 256\n",
        "        self.img_height = 256\n",
        "        self.img_channels = 3\n",
        "        self.n_train_samples = 5830\n",
        "        self.n_validation_samples = 2298\n",
        "        self.n_test_samples = 3460\n",
        "        self.n_labels = 29\n",
        "        self.epochs = epochs\n",
        "        self.n_freeze_layers = n_freeze_layers\n",
        "        self.learning_rate = learning_rate\n",
        "        self.imagenet_weights_url = None\n",
        "        self.imagenet_use_id = False\n",
        "\n",
        "    def load_model(self, model_weights=None):\n",
        "        print('Creating model...')\n",
        "        self._create()\n",
        "        print('Loading weights from {}...'.format(model_weights))\n",
        "        self.model.load_weights(model_weights)\n",
        "        print('Compiling...')\n",
        "        sgd = optimizers.SGD(lr=self.learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "        adam = optimizers.Adam(lr=self.learning_rate)\n",
        "        nadam = optimizers.Nadam(lr=self.learning_rate)\n",
        "        self.model.compile(\n",
        "            #optimizers.Adam(lr=self.learning_rate),\n",
        "            #optimizers.Nadam(),\n",
        "            optimizers.SGD(momentum=0.9),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return self.model\n",
        "\n",
        "    def train(self):\n",
        "        print('Creating model...')\n",
        "        self._create()\n",
        "\n",
        "        self._freeze_top_layers()\n",
        "\n",
        "        print('Loading weights...')\n",
        "        self._load_pretrained_weights()\n",
        "\n",
        "        print('Compiling...')\n",
        "        self.model.compile(\n",
        "            #optimizers.Adam(lr=self.learning_rate),\n",
        "            #optimizers.Nadam(),\n",
        "            optimizers.SGD(momentum=0.9),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        #print(self.model.summary())\n",
        "\n",
        "        # Data generators for the model\n",
        "        train_gen = self._get_train_generator()\n",
        "        validation_gen = self._get_validation_generator()\n",
        "\n",
        "        print('Training model...')\n",
        "        self.model.fit_generator(\n",
        "            train_gen,\n",
        "            steps_per_epoch=int(self.n_train_samples / self.batch_size),\n",
        "            validation_data=validation_gen,\n",
        "            validation_steps=int(self.n_validation_samples / self.batch_size),\n",
        "            epochs=self.epochs,\n",
        "            callbacks=self._get_callbacks(),\n",
        "            verbose=self.verbose\n",
        "        )\n",
        "\n",
        "    def predict_validation(self, model_weights):\n",
        "        img_paths = self._get_validation_image_paths()\n",
        "        return self._predict(model_weights, img_paths)\n",
        "\n",
        "    def predict_test(self, model_weights):\n",
        "        img_paths = self._get_test_image_paths()\n",
        "        return self._predict(model_weights, img_paths)\n",
        "\n",
        "    @staticmethod\n",
        "    def write_predictions(predictions, file_name='predictions.csv'):\n",
        "        with open(file_name, 'w') as file:\n",
        "            file.write('ID,Label')\n",
        "            for index, value in enumerate(predictions):\n",
        "                file.write('\\n{0},{1}'.format(index + 1, value))\n",
        "\n",
        "    @staticmethod\n",
        "    def show_progress_bar(iteration, total, bar_length=50):\n",
        "        percent = int(round((iteration / total) * 100))\n",
        "        nb_bar_fill = int(round((bar_length * percent) / 100))\n",
        "        bar_fill = '#' * nb_bar_fill\n",
        "        bar_empty = ' ' * (bar_length - nb_bar_fill)\n",
        "        sys.stdout.write(\"\\r  [{0}] {1}%\".format(str(bar_fill + bar_empty), percent))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    def _predict(self, model_weights, img_paths):\n",
        "        self.load_model(model_weights)\n",
        "\n",
        "        label_map = self._get_label_map()\n",
        "        img_count = len(img_paths)\n",
        "        y_predictions = np.zeros(img_count, dtype=np.int8)\n",
        "\n",
        "        for i, (img_num, img_path) in enumerate(img_paths):\n",
        "            ModelBase.show_progress_bar(i, img_count)\n",
        "            img_data = self._load_image(img_path)\n",
        "            if isinstance(self.model, Sequential):\n",
        "                pred_index = self.model.predict_classes(img_data)[0]\n",
        "            else:\n",
        "                predictions = self.model.predict(img_data)\n",
        "                pred_index = np.argmax(predictions, axis=1)[0]\n",
        "            pred_label = label_map[pred_index]\n",
        "            y_predictions[img_num-1] = pred_label\n",
        "\n",
        "        return y_predictions\n",
        "\n",
        "    def _get_label_map(self):\n",
        "        # We need the ImageDataGenerator used to train the model\n",
        "        # because it contains a mapping between classes and indices\n",
        "        train_gen = self._get_train_generator()\n",
        "\n",
        "        # Reverse keys and values so values becomes keys\n",
        "        label_map = {v: int(k) for k, v in train_gen.class_indices.items()}\n",
        "\n",
        "        return label_map\n",
        "\n",
        "    def _load_image(self, image_path):\n",
        "        img = image.load_img(image_path, target_size=(self.img_width, self.img_height))\n",
        "        x = image.img_to_array(img)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        return preprocess_input(x)\n",
        "\n",
        "    def _get_test_image_paths(self):\n",
        "        final_list = []\n",
        "        for img_name in os.listdir(self.test_data_dir):\n",
        "            img_number = int(re.findall(r'\\d+', img_name)[0])\n",
        "            img_path = os.path.join(self.test_data_dir, img_name)\n",
        "            final_list.append((img_number, img_path))\n",
        "        return final_list\n",
        "\n",
        "    def _get_validation_image_paths(self):\n",
        "        final_list = []\n",
        "        for sub_dir in os.listdir(self.validation_data_dir):\n",
        "            sub_dir_path = os.path.join(self.validation_data_dir, sub_dir)\n",
        "            for img_name in os.listdir(sub_dir_path):\n",
        "                img_number = int(re.findall(r'\\d+', img_name)[0])\n",
        "                img_path = os.path.join(sub_dir_path, img_name)\n",
        "                final_list.append((img_number, img_path))\n",
        "        return final_list\n",
        "\n",
        "    def _get_validation_generator(self):\n",
        "        return ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input\n",
        "        ).flow_from_directory(\n",
        "            self.validation_data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\"\n",
        "        )\n",
        "\n",
        "    def _get_train_generator(self):\n",
        "        return ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input\n",
        "        ).flow_from_directory(\n",
        "            self.train_data_dir,\n",
        "            target_size=(self.img_height, self.img_width),\n",
        "            batch_size=self.batch_size,\n",
        "            class_mode=\"categorical\"\n",
        "        )\n",
        "\n",
        "    def _load_pretrained_weights(self):\n",
        "        saved_weights_path = self._find_saved_weights()\n",
        "        if saved_weights_path is not None:\n",
        "            print('Loading saved weights from: {}'.format(saved_weights_path))\n",
        "            self.model.load_weights(saved_weights_path)\n",
        "\n",
        "        elif self.imagenet_weights_url is not None and len(self.imagenet_weights_url) > 0:\n",
        "            print('Loading imagenet weights...')\n",
        "            model_weights_path = 'saved_weights/{}'.format(os.path.basename(self.imagenet_weights_url))\n",
        "            if os.path.isfile(model_weights_path):\n",
        "                print('Model file already downloaded')\n",
        "            else:\n",
        "                # Download pre-trained weights\n",
        "                print('Downloading {}...'.format(model_weights_path))\n",
        "                urllib.request.urlretrieve(self.imagenet_weights_url, model_weights_path)\n",
        "            self._load_weights_from_file(model_weights_path)\n",
        "        else:\n",
        "            print('No pre-trained weights loaded!')\n",
        "\n",
        "    def _create(self):\n",
        "        raise NotImplementedError('subclasses must override _create()')\n",
        "\n",
        "    def _freeze_top_layers(self):\n",
        "        if self.n_freeze_layers > 1:\n",
        "            print(\"Freezing {} layers\".format(self.n_freeze_layers))\n",
        "            for layer in self.model.layers[:self.n_freeze_layers]:\n",
        "                layer.trainable = False\n",
        "            for layer in self.model.layers[self.n_freeze_layers:]:\n",
        "                layer.trainable = True\n",
        "\n",
        "    def _get_callbacks(self):\n",
        "        # Define model checkpoint\n",
        "        checkpoint = ModelCheckpoint(\n",
        "            'saved_weights/%s-epoch{epoch:02d}-acc{acc:.2f}-loss{loss:.2f}'\n",
        "            '-valacc{val_acc:.2f}-valloss{val_loss:.2f}.hdf5' % self.model_name,\n",
        "            monitor='val_acc',\n",
        "            save_best_only=False,\n",
        "            save_weights_only=True,\n",
        "            mode='auto',\n",
        "            period=1,\n",
        "            verbose=self.verbose\n",
        "        )\n",
        "\n",
        "        # Define early stopping\n",
        "        early_stop = EarlyStopping(\n",
        "            monitor='val_acc',\n",
        "            min_delta=0,\n",
        "            patience=10,\n",
        "            mode='auto',\n",
        "            verbose=self.verbose\n",
        "        )\n",
        "        \n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-5)\n",
        "\n",
        "        return [checkpoint, early_stop, reduce_lr]\n",
        "\n",
        "    def _find_saved_weights(self, models_dir='./saved_weights/'):\n",
        "        if not os.path.isdir(models_dir):\n",
        "            return None\n",
        "\n",
        "        list_of_files = sorted(os.listdir(models_dir))\n",
        "        best_model = None\n",
        "        best_acc = 0\n",
        "        for f in list_of_files:\n",
        "            if f.startswith(self.model_name):\n",
        "                values = re.findall('val[^\\d]*(\\d+\\.\\d*)', f)\n",
        "                acc = float(values[0])\n",
        "                if acc > best_acc:\n",
        "                    best_acc = acc\n",
        "                    best_model = os.path.join(models_dir, f)\n",
        "        return best_model\n",
        "\n",
        "    def _load_weights_from_file(self, file_path):\n",
        "        print('Loading weights from {}...'.format(file_path))\n",
        "\n",
        "        layer_indices = {l.name: i for (i, l) in enumerate(self.model.layers)}\n",
        "\n",
        "        # Load weights from the downloaded file\n",
        "        with h5py.File(file_path) as model_weights_file:\n",
        "            layer_names = model_weights_file.attrs['layer_names']\n",
        "            for i, layer_name in enumerate(layer_names):\n",
        "                level_0 = model_weights_file[layer_name]\n",
        "                transferred_weights = []\n",
        "                for k0 in level_0.keys():\n",
        "                    level_1 = level_0[k0]\n",
        "                    if hasattr(level_1, 'keys'):\n",
        "                        for k1 in level_1.keys():\n",
        "                            transferred_weights.append(level_1[k1][()])\n",
        "                    else:\n",
        "                        transferred_weights.append(level_0[k0][()])\n",
        "                if self.imagenet_use_id:\n",
        "                    layer_index = i\n",
        "                else:\n",
        "                    layer_key = layer_name.decode('UTF-8')\n",
        "                    if layer_key not in layer_indices:\n",
        "                        continue\n",
        "                    layer_index = layer_indices[layer_key]\n",
        "                self.model.layers[layer_index].set_weights(transferred_weights)\n",
        "        print('Done loading weights')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rNQRrAeN4CQX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "class ModelInceptionV3Take2(ModelBase):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        ModelBase.__init__(self, *args, **kwargs)\n",
        "\n",
        "    def _create(self):\n",
        "        base_model = applications.InceptionV3(\n",
        "            include_top=False,\n",
        "            input_shape=(self.img_width, self.img_height, self.img_channels)\n",
        "        )\n",
        "        output_layer = base_model.output\n",
        "        output_layer = GlobalAveragePooling2D(name='avg_pool')(output_layer)\n",
        "        output_layer = Dense(256, activation='relu')(output_layer)\n",
        "        output_layer = Dropout(0.5)(output_layer)\n",
        "        output_layer = Dense(self.n_labels, activation='softmax', name='predictions')(output_layer)\n",
        "        self.model = Model(inputs=base_model.input, outputs=output_layer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A-NYGTMA4FE2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = ModelInceptionV3Take2(\n",
        "    model_name='model-15-inception-v3-take3',\n",
        "    n_freeze_layers=0,\n",
        "    batch_size=64,\n",
        "    verbose=1,\n",
        "    epochs=300\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiDxVTol4OB2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 3927
        },
        "outputId": "189fa975-7ef9-49d6-a6b2-c7763bc9d440",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525673038823,
          "user_tz": -120,
          "elapsed": 9628180,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating model...\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 5s 0us/step\n",
            "Loading weights...\n",
            "No pre-trained weights loaded!\n",
            "Compiling...\n",
            "Found 70208 images belonging to 29 classes.\n",
            "Found 2298 images belonging to 29 classes.\n",
            "Training model...\n",
            "Epoch 1/300\n",
            "91/91 [==============================] - 190s 2s/step - loss: 2.4741 - acc: 0.2886 - val_loss: 3.3572 - val_acc: 0.2379\n",
            "\n",
            "Epoch 00001: saving model to saved_weights/model-15-inception-v3-take3-epoch01-acc0.29-loss2.47-valacc0.24-valloss3.36.hdf5\n",
            "Epoch 2/300\n",
            "41/91 [============>.................] - ETA: 1:23 - loss: 1.5905 - acc: 0.5225"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 1.4171 - acc: 0.5628 - val_loss: 2.2122 - val_acc: 0.3795\n",
            "\n",
            "Epoch 00002: saving model to saved_weights/model-15-inception-v3-take3-epoch02-acc0.56-loss1.42-valacc0.38-valloss2.21.hdf5\n",
            "Epoch 3/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 1.1295 - acc: 0.6429 - val_loss: 1.4330 - val_acc: 0.5629\n",
            "\n",
            "Epoch 00003: saving model to saved_weights/model-15-inception-v3-take3-epoch03-acc0.64-loss1.13-valacc0.56-valloss1.43.hdf5\n",
            "Epoch 4/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.8998 - acc: 0.7141 - val_loss: 2.5088 - val_acc: 0.4402\n",
            "\n",
            "Epoch 00004: saving model to saved_weights/model-15-inception-v3-take3-epoch04-acc0.71-loss0.90-valacc0.44-valloss2.51.hdf5\n",
            "Epoch 5/300\n",
            " 9/91 [=>............................] - ETA: 2:17 - loss: 0.8736 - acc: 0.7188"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.8130 - acc: 0.7378 - val_loss: 1.4456 - val_acc: 0.6098\n",
            "\n",
            "Epoch 00005: saving model to saved_weights/model-15-inception-v3-take3-epoch05-acc0.74-loss0.81-valacc0.61-valloss1.45.hdf5\n",
            "Epoch 6/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.6743 - acc: 0.7843 - val_loss: 0.9390 - val_acc: 0.7121\n",
            "\n",
            "Epoch 00006: saving model to saved_weights/model-15-inception-v3-take3-epoch06-acc0.78-loss0.67-valacc0.71-valloss0.94.hdf5\n",
            "Epoch 7/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.6188 - acc: 0.8007 - val_loss: 1.4249 - val_acc: 0.6076\n",
            "\n",
            "Epoch 00007: saving model to saved_weights/model-15-inception-v3-take3-epoch07-acc0.80-loss0.62-valacc0.61-valloss1.42.hdf5\n",
            "Epoch 8/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.5771 - acc: 0.8281"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.5765 - acc: 0.8070 - val_loss: 1.1056 - val_acc: 0.6661\n",
            "\n",
            "Epoch 00008: saving model to saved_weights/model-15-inception-v3-take3-epoch08-acc0.81-loss0.58-valacc0.67-valloss1.11.hdf5\n",
            "Epoch 9/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.5236 - acc: 0.8343 - val_loss: 0.9495 - val_acc: 0.7210\n",
            "\n",
            "Epoch 00009: saving model to saved_weights/model-15-inception-v3-take3-epoch09-acc0.83-loss0.52-valacc0.72-valloss0.95.hdf5\n",
            "Epoch 10/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.4661 - acc: 0.8486 - val_loss: 0.9884 - val_acc: 0.6987\n",
            "\n",
            "Epoch 00010: saving model to saved_weights/model-15-inception-v3-take3-epoch10-acc0.85-loss0.47-valacc0.70-valloss0.99.hdf5\n",
            "Epoch 11/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.4225 - acc: 0.8568"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.4390 - acc: 0.8661 - val_loss: 1.0294 - val_acc: 0.7067\n",
            "\n",
            "Epoch 00011: saving model to saved_weights/model-15-inception-v3-take3-epoch11-acc0.87-loss0.44-valacc0.71-valloss1.03.hdf5\n",
            "Epoch 12/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.3747 - acc: 0.8798 - val_loss: 0.4285 - val_acc: 0.8661\n",
            "\n",
            "Epoch 00012: saving model to saved_weights/model-15-inception-v3-take3-epoch12-acc0.88-loss0.37-valacc0.87-valloss0.43.hdf5\n",
            "Epoch 13/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.2039 - acc: 0.9327 - val_loss: 0.3174 - val_acc: 0.8996\n",
            "\n",
            "Epoch 00013: saving model to saved_weights/model-15-inception-v3-take3-epoch13-acc0.93-loss0.20-valacc0.90-valloss0.32.hdf5\n",
            "Epoch 14/300\n",
            " 6/91 [>.............................] - ETA: 2:21 - loss: 0.2329 - acc: 0.9271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.1742 - acc: 0.9487 - val_loss: 0.2799 - val_acc: 0.9049\n",
            "\n",
            "Epoch 00014: saving model to saved_weights/model-15-inception-v3-take3-epoch14-acc0.95-loss0.17-valacc0.90-valloss0.28.hdf5\n",
            "Epoch 15/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.1575 - acc: 0.9492 - val_loss: 0.2923 - val_acc: 0.9027\n",
            "\n",
            "Epoch 00015: saving model to saved_weights/model-15-inception-v3-take3-epoch15-acc0.95-loss0.16-valacc0.90-valloss0.29.hdf5\n",
            "Epoch 16/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.1408 - acc: 0.9521 - val_loss: 0.3151 - val_acc: 0.9022\n",
            "\n",
            "Epoch 00016: saving model to saved_weights/model-15-inception-v3-take3-epoch16-acc0.95-loss0.14-valacc0.90-valloss0.32.hdf5\n",
            "Epoch 17/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.1089 - acc: 0.9531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.1433 - acc: 0.9542 - val_loss: 0.3191 - val_acc: 0.8969\n",
            "\n",
            "Epoch 00017: saving model to saved_weights/model-15-inception-v3-take3-epoch17-acc0.95-loss0.14-valacc0.90-valloss0.32.hdf5\n",
            "Epoch 18/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.1283 - acc: 0.9560 - val_loss: 0.2771 - val_acc: 0.9134\n",
            "\n",
            "Epoch 00018: saving model to saved_weights/model-15-inception-v3-take3-epoch18-acc0.96-loss0.13-valacc0.91-valloss0.28.hdf5\n",
            "Epoch 19/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.1454 - acc: 0.9530 - val_loss: 0.2703 - val_acc: 0.9143\n",
            "\n",
            "Epoch 00019: saving model to saved_weights/model-15-inception-v3-take3-epoch19-acc0.95-loss0.15-valacc0.91-valloss0.27.hdf5\n",
            "Epoch 20/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.1372 - acc: 0.9453"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.1191 - acc: 0.9586 - val_loss: 0.2940 - val_acc: 0.9058\n",
            "\n",
            "Epoch 00020: saving model to saved_weights/model-15-inception-v3-take3-epoch20-acc0.96-loss0.12-valacc0.91-valloss0.29.hdf5\n",
            "Epoch 21/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.1138 - acc: 0.9622 - val_loss: 0.3309 - val_acc: 0.8982\n",
            "\n",
            "Epoch 00021: saving model to saved_weights/model-15-inception-v3-take3-epoch21-acc0.96-loss0.11-valacc0.90-valloss0.33.hdf5\n",
            "Epoch 22/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.1126 - acc: 0.9636 - val_loss: 0.2744 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00022: saving model to saved_weights/model-15-inception-v3-take3-epoch22-acc0.96-loss0.11-valacc0.92-valloss0.27.hdf5\n",
            "Epoch 23/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.1248 - acc: 0.9635"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.1104 - acc: 0.9639 - val_loss: 0.2617 - val_acc: 0.9183\n",
            "\n",
            "Epoch 00023: saving model to saved_weights/model-15-inception-v3-take3-epoch23-acc0.96-loss0.11-valacc0.92-valloss0.26.hdf5\n",
            "Epoch 24/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0999 - acc: 0.9674 - val_loss: 0.2835 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00024: saving model to saved_weights/model-15-inception-v3-take3-epoch24-acc0.97-loss0.10-valacc0.91-valloss0.28.hdf5\n",
            "Epoch 25/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0795 - acc: 0.9766 - val_loss: 0.2623 - val_acc: 0.9174\n",
            "\n",
            "Epoch 00025: saving model to saved_weights/model-15-inception-v3-take3-epoch25-acc0.98-loss0.08-valacc0.92-valloss0.26.hdf5\n",
            "Epoch 26/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0566 - acc: 0.9818"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0627 - acc: 0.9804 - val_loss: 0.2801 - val_acc: 0.9214\n",
            "\n",
            "Epoch 00026: saving model to saved_weights/model-15-inception-v3-take3-epoch26-acc0.98-loss0.06-valacc0.92-valloss0.28.hdf5\n",
            "Epoch 27/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0604 - acc: 0.9804 - val_loss: 0.2507 - val_acc: 0.9241\n",
            "\n",
            "Epoch 00027: saving model to saved_weights/model-15-inception-v3-take3-epoch27-acc0.98-loss0.06-valacc0.92-valloss0.25.hdf5\n",
            "Epoch 28/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0641 - acc: 0.9809 - val_loss: 0.2608 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00028: saving model to saved_weights/model-15-inception-v3-take3-epoch28-acc0.98-loss0.06-valacc0.93-valloss0.26.hdf5\n",
            "Epoch 29/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0649 - acc: 0.9740"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0604 - acc: 0.9809 - val_loss: 0.2995 - val_acc: 0.9094\n",
            "\n",
            "Epoch 00029: saving model to saved_weights/model-15-inception-v3-take3-epoch29-acc0.98-loss0.06-valacc0.91-valloss0.30.hdf5\n",
            "Epoch 30/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0590 - acc: 0.9820 - val_loss: 0.2596 - val_acc: 0.9254\n",
            "\n",
            "Epoch 00030: saving model to saved_weights/model-15-inception-v3-take3-epoch30-acc0.98-loss0.06-valacc0.93-valloss0.26.hdf5\n",
            "Epoch 31/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0623 - acc: 0.9779 - val_loss: 0.3267 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00031: saving model to saved_weights/model-15-inception-v3-take3-epoch31-acc0.98-loss0.06-valacc0.91-valloss0.33.hdf5\n",
            "Epoch 32/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0400 - acc: 0.9818"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0645 - acc: 0.9794 - val_loss: 0.2614 - val_acc: 0.9290\n",
            "\n",
            "Epoch 00032: saving model to saved_weights/model-15-inception-v3-take3-epoch32-acc0.98-loss0.06-valacc0.93-valloss0.26.hdf5\n",
            "Epoch 33/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0550 - acc: 0.9825 - val_loss: 0.2478 - val_acc: 0.9299\n",
            "\n",
            "Epoch 00033: saving model to saved_weights/model-15-inception-v3-take3-epoch33-acc0.98-loss0.05-valacc0.93-valloss0.25.hdf5\n",
            "Epoch 34/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0435 - acc: 0.9875 - val_loss: 0.2475 - val_acc: 0.9308\n",
            "\n",
            "Epoch 00034: saving model to saved_weights/model-15-inception-v3-take3-epoch34-acc0.99-loss0.04-valacc0.93-valloss0.25.hdf5\n",
            "Epoch 35/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0510 - acc: 0.9870"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0468 - acc: 0.9840 - val_loss: 0.2459 - val_acc: 0.9295\n",
            "\n",
            "Epoch 00035: saving model to saved_weights/model-15-inception-v3-take3-epoch35-acc0.98-loss0.05-valacc0.93-valloss0.25.hdf5\n",
            "Epoch 36/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0422 - acc: 0.9880 - val_loss: 0.2456 - val_acc: 0.9339\n",
            "\n",
            "Epoch 00036: saving model to saved_weights/model-15-inception-v3-take3-epoch36-acc0.99-loss0.04-valacc0.93-valloss0.25.hdf5\n",
            "Epoch 37/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0376 - acc: 0.9885 - val_loss: 0.2490 - val_acc: 0.9330\n",
            "\n",
            "Epoch 00037: saving model to saved_weights/model-15-inception-v3-take3-epoch37-acc0.99-loss0.04-valacc0.93-valloss0.25.hdf5\n",
            "Epoch 38/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0383 - acc: 0.9896"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0338 - acc: 0.9899 - val_loss: 0.2395 - val_acc: 0.9321\n",
            "\n",
            "Epoch 00038: saving model to saved_weights/model-15-inception-v3-take3-epoch38-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\n",
            "Epoch 39/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0313 - acc: 0.9909 - val_loss: 0.2431 - val_acc: 0.9335\n",
            "\n",
            "Epoch 00039: saving model to saved_weights/model-15-inception-v3-take3-epoch39-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\n",
            "Epoch 40/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0266 - acc: 0.9930 - val_loss: 0.2416 - val_acc: 0.9353\n",
            "\n",
            "Epoch 00040: saving model to saved_weights/model-15-inception-v3-take3-epoch40-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 41/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0342 - acc: 0.9896"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0311 - acc: 0.9921 - val_loss: 0.2391 - val_acc: 0.9348\n",
            "\n",
            "Epoch 00041: saving model to saved_weights/model-15-inception-v3-take3-epoch41-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\n",
            "Epoch 42/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0311 - acc: 0.9911 - val_loss: 0.2439 - val_acc: 0.9313\n",
            "\n",
            "Epoch 00042: saving model to saved_weights/model-15-inception-v3-take3-epoch42-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\n",
            "Epoch 43/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0295 - acc: 0.9923 - val_loss: 0.2370 - val_acc: 0.9353\n",
            "\n",
            "Epoch 00043: saving model to saved_weights/model-15-inception-v3-take3-epoch43-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 44/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0204 - acc: 0.9974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0269 - acc: 0.9926 - val_loss: 0.2353 - val_acc: 0.9353\n",
            "\n",
            "Epoch 00044: saving model to saved_weights/model-15-inception-v3-take3-epoch44-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 45/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0319 - acc: 0.9919 - val_loss: 0.2335 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00045: saving model to saved_weights/model-15-inception-v3-take3-epoch45-acc0.99-loss0.03-valacc0.94-valloss0.23.hdf5\n",
            "Epoch 46/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0294 - acc: 0.9916 - val_loss: 0.2430 - val_acc: 0.9353\n",
            "\n",
            "Epoch 00046: saving model to saved_weights/model-15-inception-v3-take3-epoch46-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 47/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0590 - acc: 0.9844"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0317 - acc: 0.9906 - val_loss: 0.2473 - val_acc: 0.9330\n",
            "\n",
            "Epoch 00047: saving model to saved_weights/model-15-inception-v3-take3-epoch47-acc0.99-loss0.03-valacc0.93-valloss0.25.hdf5\n",
            "Epoch 48/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0279 - acc: 0.9914 - val_loss: 0.2393 - val_acc: 0.9344\n",
            "\n",
            "Epoch 00048: saving model to saved_weights/model-15-inception-v3-take3-epoch48-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\n",
            "Epoch 49/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0256 - acc: 0.9933 - val_loss: 0.2398 - val_acc: 0.9366\n",
            "\n",
            "Epoch 00049: saving model to saved_weights/model-15-inception-v3-take3-epoch49-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 50/300\n",
            " 6/91 [>.............................] - ETA: 2:21 - loss: 0.0433 - acc: 0.9870"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0308 - acc: 0.9906 - val_loss: 0.2463 - val_acc: 0.9326\n",
            "\n",
            "Epoch 00050: saving model to saved_weights/model-15-inception-v3-take3-epoch50-acc0.99-loss0.03-valacc0.93-valloss0.25.hdf5\n",
            "Epoch 51/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0249 - acc: 0.9936 - val_loss: 0.2413 - val_acc: 0.9357\n",
            "\n",
            "Epoch 00051: saving model to saved_weights/model-15-inception-v3-take3-epoch51-acc0.99-loss0.02-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 52/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0273 - acc: 0.9935 - val_loss: 0.2374 - val_acc: 0.9353\n",
            "\n",
            "Epoch 00052: saving model to saved_weights/model-15-inception-v3-take3-epoch52-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 53/300\n",
            " 6/91 [>.............................] - ETA: 2:22 - loss: 0.0309 - acc: 0.9922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "91/91 [==============================] - 173s 2s/step - loss: 0.0286 - acc: 0.9924 - val_loss: 0.2394 - val_acc: 0.9362\n",
            "\n",
            "Epoch 00053: saving model to saved_weights/model-15-inception-v3-take3-epoch53-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 54/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0272 - acc: 0.9935 - val_loss: 0.2373 - val_acc: 0.9362\n",
            "\n",
            "Epoch 00054: saving model to saved_weights/model-15-inception-v3-take3-epoch54-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 55/300\n",
            "91/91 [==============================] - 173s 2s/step - loss: 0.0218 - acc: 0.9950 - val_loss: 0.2382 - val_acc: 0.9362\n",
            "\n",
            "Epoch 00055: saving model to saved_weights/model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.hdf5\n",
            "Epoch 00055: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rPCgBpoU4PdO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f541dc58-b3f4-4399-ed47-86fc850013de",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525663399902,
          "user_tz": -120,
          "elapsed": 519,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/cvml/project'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "jPS5WiRhnIvi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5a8c88c4-d594-463b-b37d-53cbc9bfc1fb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525663336573,
          "user_tz": -120,
          "elapsed": 29589,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sheikhomar/cvml.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cvml'...\n",
            "remote: Counting objects: 78328, done.\u001b[K\n",
            "remote: Total 78328 (delta 0), reused 0 (delta 0), pack-reused 78328\u001b[K\n",
            "Receiving objects: 100% (78328/78328), 476.18 MiB | 30.65 MiB/s, done.\n",
            "Resolving deltas: 100% (736/736), done.\n",
            "Checking out files: 100% (77993/77993), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ljoUemKcBtkC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "a2b385cd-2035-449e-f96f-9d3393997e91",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525673041298,
          "user_tz": -120,
          "elapsed": 2459,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ls -haltr saved_weights/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.7G\r\n",
            "-rw-r--r-- 1 root root    0 May  7 03:22 sentinel\r\n",
            "drwxr-xr-x 9 root root 4.0K May  7 03:22 \u001b[0m\u001b[01;34m..\u001b[0m/\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:27 model-15-inception-v3-take3-epoch01-acc0.29-loss2.47-valacc0.24-valloss3.36.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:30 model-15-inception-v3-take3-epoch02-acc0.56-loss1.42-valacc0.38-valloss2.21.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:33 model-15-inception-v3-take3-epoch03-acc0.64-loss1.13-valacc0.56-valloss1.43.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:36 model-15-inception-v3-take3-epoch04-acc0.71-loss0.90-valacc0.44-valloss2.51.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:39 model-15-inception-v3-take3-epoch05-acc0.74-loss0.81-valacc0.61-valloss1.45.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:42 model-15-inception-v3-take3-epoch06-acc0.78-loss0.67-valacc0.71-valloss0.94.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:45 model-15-inception-v3-take3-epoch07-acc0.80-loss0.62-valacc0.61-valloss1.42.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:47 model-15-inception-v3-take3-epoch08-acc0.81-loss0.58-valacc0.67-valloss1.11.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:50 model-15-inception-v3-take3-epoch09-acc0.83-loss0.52-valacc0.72-valloss0.95.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:53 model-15-inception-v3-take3-epoch10-acc0.85-loss0.47-valacc0.70-valloss0.99.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:56 model-15-inception-v3-take3-epoch11-acc0.87-loss0.44-valacc0.71-valloss1.03.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 03:59 model-15-inception-v3-take3-epoch12-acc0.88-loss0.37-valacc0.87-valloss0.43.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:02 model-15-inception-v3-take3-epoch13-acc0.93-loss0.20-valacc0.90-valloss0.32.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:05 model-15-inception-v3-take3-epoch14-acc0.95-loss0.17-valacc0.90-valloss0.28.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:08 model-15-inception-v3-take3-epoch15-acc0.95-loss0.16-valacc0.90-valloss0.29.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:11 model-15-inception-v3-take3-epoch16-acc0.95-loss0.14-valacc0.90-valloss0.32.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:13 model-15-inception-v3-take3-epoch17-acc0.95-loss0.14-valacc0.90-valloss0.32.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:16 model-15-inception-v3-take3-epoch18-acc0.96-loss0.13-valacc0.91-valloss0.28.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:19 model-15-inception-v3-take3-epoch19-acc0.95-loss0.15-valacc0.91-valloss0.27.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:22 model-15-inception-v3-take3-epoch20-acc0.96-loss0.12-valacc0.91-valloss0.29.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:25 model-15-inception-v3-take3-epoch21-acc0.96-loss0.11-valacc0.90-valloss0.33.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:28 model-15-inception-v3-take3-epoch22-acc0.96-loss0.11-valacc0.92-valloss0.27.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:31 model-15-inception-v3-take3-epoch23-acc0.96-loss0.11-valacc0.92-valloss0.26.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:34 model-15-inception-v3-take3-epoch24-acc0.97-loss0.10-valacc0.91-valloss0.28.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:37 model-15-inception-v3-take3-epoch25-acc0.98-loss0.08-valacc0.92-valloss0.26.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:40 model-15-inception-v3-take3-epoch26-acc0.98-loss0.06-valacc0.92-valloss0.28.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:42 model-15-inception-v3-take3-epoch27-acc0.98-loss0.06-valacc0.92-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:45 model-15-inception-v3-take3-epoch28-acc0.98-loss0.06-valacc0.93-valloss0.26.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:48 model-15-inception-v3-take3-epoch29-acc0.98-loss0.06-valacc0.91-valloss0.30.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:51 model-15-inception-v3-take3-epoch30-acc0.98-loss0.06-valacc0.93-valloss0.26.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:54 model-15-inception-v3-take3-epoch31-acc0.98-loss0.06-valacc0.91-valloss0.33.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 04:57 model-15-inception-v3-take3-epoch32-acc0.98-loss0.06-valacc0.93-valloss0.26.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:00 model-15-inception-v3-take3-epoch33-acc0.98-loss0.05-valacc0.93-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:03 model-15-inception-v3-take3-epoch34-acc0.99-loss0.04-valacc0.93-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:06 model-15-inception-v3-take3-epoch35-acc0.98-loss0.05-valacc0.93-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:08 model-15-inception-v3-take3-epoch36-acc0.99-loss0.04-valacc0.93-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:11 model-15-inception-v3-take3-epoch37-acc0.99-loss0.04-valacc0.93-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:14 model-15-inception-v3-take3-epoch38-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:17 model-15-inception-v3-take3-epoch39-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:20 model-15-inception-v3-take3-epoch40-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:23 model-15-inception-v3-take3-epoch41-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:26 model-15-inception-v3-take3-epoch42-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:29 model-15-inception-v3-take3-epoch43-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:32 model-15-inception-v3-take3-epoch44-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:35 model-15-inception-v3-take3-epoch45-acc0.99-loss0.03-valacc0.94-valloss0.23.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:37 model-15-inception-v3-take3-epoch46-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:40 model-15-inception-v3-take3-epoch47-acc0.99-loss0.03-valacc0.93-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:43 model-15-inception-v3-take3-epoch48-acc0.99-loss0.03-valacc0.93-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:46 model-15-inception-v3-take3-epoch49-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:49 model-15-inception-v3-take3-epoch50-acc0.99-loss0.03-valacc0.93-valloss0.25.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:52 model-15-inception-v3-take3-epoch51-acc0.99-loss0.02-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:55 model-15-inception-v3-take3-epoch52-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 05:58 model-15-inception-v3-take3-epoch53-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "-rw-r--r-- 1 root root  86M May  7 06:01 model-15-inception-v3-take3-epoch54-acc0.99-loss0.03-valacc0.94-valloss0.24.hdf5\r\n",
            "drwxr-xr-x 2 root root  12K May  7 06:03 \u001b[01;34m.\u001b[0m/\r\n",
            "-rw-r--r-- 1 root root  86M May  7 06:04 model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.hdf5\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29kBW0H6CTua",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('saved_weights/model-15-inception-v3-take3-epoch45-acc0.99-loss0.03-valacc0.94-valloss0.23.hdf5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbYQLJHgJG19",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download('saved_weights/model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EqfH1q15JIcV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Glrgu5ZKJI2m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "eca06cac-204a-4c69-cb9c-cd490a3d626e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525674033071,
          "user_tz": -120,
          "elapsed": 145515,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_val_pred = m.predict_validation(model_weights='saved_weights/model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating model...\n",
            "Loading weights from saved_weights/model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.hdf5...\n",
            "Compiling...\n",
            "Found 70208 images belonging to 29 classes.\n",
            "  [########                                          ] 17%"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  [##################################################] 100%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GERAIeAMPiMM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "ed832120-965c-4e9c-9dc4-4674d63ff8d2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525674047246,
          "user_tz": -120,
          "elapsed": 484,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "y_validation = pd.read_csv('Validation/valLbls.csv', header=None, names=['label'])['label']\n",
        "print(classification_report(y_validation, y_val_pred))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       1.00      0.99      1.00       116\n",
            "          2       0.86      0.84      0.85        96\n",
            "          3       0.90      0.96      0.93        94\n",
            "          4       0.99      0.99      0.99        92\n",
            "          5       0.97      0.99      0.98        88\n",
            "          6       0.96      0.83      0.89        92\n",
            "          7       0.89      0.84      0.86        92\n",
            "          8       0.83      0.89      0.86        88\n",
            "          9       0.97      0.99      0.98        88\n",
            "         10       0.96      0.91      0.94        82\n",
            "         11       0.99      0.98      0.98        86\n",
            "         12       0.93      0.96      0.94        80\n",
            "         13       0.98      1.00      0.99        80\n",
            "         14       0.89      0.96      0.92        82\n",
            "         15       0.94      0.90      0.92        82\n",
            "         16       0.94      0.99      0.96        82\n",
            "         17       1.00      0.99      0.99        80\n",
            "         18       0.97      0.97      0.97        80\n",
            "         19       1.00      0.99      0.99        78\n",
            "         20       0.81      0.96      0.88        74\n",
            "         21       0.95      1.00      0.97        76\n",
            "         22       0.96      0.95      0.95        74\n",
            "         23       0.96      0.83      0.89        66\n",
            "         24       0.97      0.94      0.96        72\n",
            "         25       0.72      0.56      0.63        64\n",
            "         26       0.96      0.98      0.97        66\n",
            "         27       0.97      1.00      0.98        56\n",
            "         28       0.93      0.98      0.95        52\n",
            "         29       0.97      0.97      0.97        40\n",
            "\n",
            "avg / total       0.94      0.94      0.94      2298\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JBJkMD3hQi3a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "eadcad2f-19d7-4384-f14f-1cf828ace68a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525674309456,
          "user_tz": -120,
          "elapsed": 207396,
          "user": {
            "displayName": "Omar Ali Sheikh-Omar",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102912719476911650914"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "y_test_pred = m.predict_test(model_weights='saved_weights/model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating model...\n",
            "Loading weights from saved_weights/model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.hdf5...\n",
            "Compiling...\n",
            "Found 70208 images belonging to 29 classes.\n",
            "  [######                                            ] 11%"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  [##################################################] 100%"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BClNuvq4Q0zw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "ModelBase.write_predictions(y_test_pred, file_name='test-pred-model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wWRTDHnjRFUZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "files.download('test-pred-model-15-inception-v3-take3-epoch55-acc1.00-loss0.02-valacc0.94-valloss0.24.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_YgQG8ykRK4I",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}